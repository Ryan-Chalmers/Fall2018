= ECSE 429

== Intro to Software Quality Assurance

=== Basic Terminology

==== Error, Fault, and Failure

image::images/ECSE429LectureNotes-e11a2.png[align=center]

image::images/ECSE429LectureNotes-d1749.png[align=center]

* mistake: people commit errors
* defect: a mistake in software can lead to defect
* failure: occurs when defect executes
* incident: consequence of failures-failure occurrence may or may not be apparent
to user

==== Defects Root Cause and Effect

* Root cause of defect: earliest action/condition that contributed to creating
defect
* Root Cause Analysis: Identify root cause to reduce occurence of similar
defects in the future
* Effects of a defect: observed by user/customer, product owner


==== Nine Causes of Software Defects

1. Faulty requirements definitions
2. Client-developer communication
3. Deliberate deviations from software requirements
4. Logical design errors
5. Coding errors
6. non-compliance with documentation and coding instructions
7. Shortcomings of the testing process
8. Procedure errors
9. Documentation errors

=== Software Quality

==== Conformance to Requirements

* Lack of bugs:
** Low defect rate
** well documented defects

* High reliability/Availability
** *Mean time to failure* the probability of failure free operation until a
specified time
** *Mean time between failures* the probability that the system is up and
running at any given point in time

==== Software Quality Challenge

* The uniqueness of the software product
** High complexity: pervasive in an increasing number of industries
** Invisibility of the product
** Limited opportunities to detect defect compared to other industries
*** Development, not production

* The environments in which software is developed
** Contracted
** Subjected to customer-supplier relationship
** Requirements for teamwork
** etc.

=== Software Quality Factors

==== McCaul Method

image::images/ECSE429LectureNotes-83059.png[align=center]

* Correctness
** Accuracy and completeness of required output
** up to date

* Reliability
** First failure
** Max failure rate

* Efficiency
** hardware resources needed to perform function

* Integrity
** System security

* UX
* Maintainability
** Effort to identify and fix errors

* Flexibility
* Testability
** Support for testing, traceability

* Portability
** Adaptation to other environments

* Reusability
** Use of software components for other projects

* Interoperability
** Ability to interface with other components/systems

=== SQA

==== Objectives

1. Acceptable confidence that software will conform to functional technical
requirements
2. Acceptable confidence that software will conform to managerial scheduling
and budgetary requirements
3. Activities for the improvement/efficiency of software software development,
software maintenance, and software quality assurance activities

==== Three key principles

1. know what you are doing
* what is being built, how its being built, what it does
* Management structure
* Reporting Policies
* Tracking

2. know what you should be doing
* Having explicit requirements and specifications
* Requirements analysis
* Acceptance tests
* User feedback

3. know how to measure the difference
* Measure comparing what is being done with what should be done
* Includes:
** Formal methods: prove mathematically
** Testing: explicit input to exercise software and check for expected output
** Inspections: human examination of requirements, design, code... checklists\
** Metrics: measure a known set of properties related so quality

==== Software Quality Shrine

image::images/ECSE429LectureNotes-09f32.png[align=center]

==== Verification vs Validation

* Verification: are we building the product right?
* Validation: are we building the right product?

image::images/ECSE429LectureNotes-4e094.png[align=center]

==== SQA Includes

* Defect prevention
** Prevents defects from occurring in the first place
** Activities: training, planning, simulation

* Defect detection
** finds defects in a software artifact
** Activities: inspections, testing, or measuring

* Defect removal
** Isolation, correction, verification of fixes
** Activities: fault isolation, fault analysis, regression testing

* Typical Activities of an SQA Process
** Requirements validation
** design verification
** Static code checking
** dynamic testing
** Process engineering and standards
** Metrics and continuous improvement

image::images/ECSE429LectureNotes-90e56.png[align=center]

=== Software Development Lifecycle Models

* Sequential and Iterative development processes
* Continuous Integration (CI)
** A software development process where a continuous integration server rebuilds
a branch of source code ever time code is committed to the source control
system

* Continuous Deployment
** A software production process where changes are automatically deployed to
production without any manual intervention

* Continuous Delivery
** A software production process where the software can be released to
production at any time with as much automation as possible for each step


== Software Testing

=== Why is Testing Difficult

* Upper limit to total number of test cases
* *continuity property* small differences in operating conditions will not result
in dramatically different behavior -> *not true in software!*

=== Seven Testing Principles

1. Program testing can be used to show the presence of bugs, but never
their absence
2. Exhaustive testing is impossible
3. Early testing saves time and money
4. Defects cluster together
5. Pesticide Paradox: a system tends to build a resistance to a particular
technique
6. Testing is context dependent
7. Absence of errors is a fallacy

=== Test Levels

image::images/ECSE429LectureNotes-b7b3f.png[align=center]

==== Component/Unit Testing

==== Integration Testing

==== System Testing

==== Acceptance Testing

* User level: fitness for use by intended users
* Operational
* Contractual: check with respect to contract's acceptance criteria
* Alpha and Beta

=== Test Types

* Functional vs. non-functional
** Functional: evaluate that the system performs with respects to requirements
** non-functional: evaluate characteristics system as a whole

* Black-box vs. White-box
** Black-box (functional)
** White-box: aim to derive tests based on systems internal structure

==== Oracles and Test Coverage

==== Regression Testing

* Different *scopes*
** Local: direct testing of the code changed or added
** Surrounding: testing of function supported or directly impacted by the change
** Confidence: predefined suite of tests routinely run after any change is
made to product/system

==== Maintenance Testing

* Goal:
** Carried after system is in production
** Evaluate success + ensure lack of side effects

* Triggers for Maintenance
** Modification
** Migration
** Retirement

* Impact analysis for maintenance
** Evaluate the planned/execute changes

=== Test Activities and Processes

==== Test Planning

* Define objectives
* Define approach on how to meet test objectives within constraints

==== Test Monitoring and Control

* Compare actual progress against the test plan using monitoring metrics
* Evaluate exit criteria (check test results against coverage criterial)

==== Test Analysis

* BDD
* Determines what to test in terms of measurable coverage criteria
** Identify testable features
** Define and prioritize associated test conditions
** Capture traceability

* Analyze test basis to identify testable features

==== Test Design

* Elaborate test condition s into high-level test cases
* Design and prioritize test cases
* Identify necessary data to support test conditions and cases
* Design test environment and identify required infrastructure and tools
* Capture traceability between test basis, test conditions, test cases, and
test procedures

==== Test Implementation

* Do we now have everything in place to run the tests?
* Create test software for test execution
* Preparing test data and load into test environment
* Verify and update traceability between the test basis, test conditions,
test cases, test procedures, and test suites

==== Test Execution

* Run test suites in accordance with test execution schedule
** Execute
** Compare results
** Analyze anomalies
** Report defects based on the observed failures
** Log
** Verify and update traceability

==== Test Completion

* Collect data from completed test activities to consolidate experience
* Occurs at project milestones
** Check if all defect reports are closed
** Create a test summary report
** Analyze lessons learned

==== Importance of Traceability

* Bidirectional traceability between test basis and test work product
** Analyze the impact of changes
** Auditing and certification
** Improve understandabilty of various test reports

==== Test Driven Development

* Listen->Test->Code->Design
* Listen to customers while gathering requirements, develop test cases, code
the program, (re-)design / refactor / clean up as more code is added to the
system

=== Test Automation

image::images/ECSE429LectureNotes-05076.png[align=center]

=== In Class Quiz

1. Valid objective for testing? find as many failures as possible so that defects
can be identified and corrected
2. Difference between testing and debugging? testing shows failures caused by
defects; debugging finds, analyzes, and removes the cause of failures in the
software
3. Failure in testing or production? product crashed when the user selected
and option in a dialog box
4. Which is a key principle of software testing? it is impossible to test
all input and precondition combinations of a system
5. In what way can testing be a part of Quality Assurance? It reduces the level
of risk to the quality of the system
6. Which of the following is performed during the test analysis activity?
evaluating test basis for testability
7. How can white-box testing be applied during acceptance testing? To check if
all work process flows have been covered

== Static Validation and Verification Techniques
